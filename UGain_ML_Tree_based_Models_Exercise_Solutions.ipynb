{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **UGain ML Tree-based Models Exercise Solutions Notebook**"
      ],
      "metadata": {
        "id": "KrE9FZvJo_1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Libraries**"
      ],
      "metadata": {
        "id": "zzyz8bLHpHLI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-rU_pRdAJEW",
        "outputId": "0b49307c-b628-4aa0-c2d9-b46032d71bd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting auto-sklearn\n",
            "  Downloading auto-sklearn-0.15.0.tar.gz (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 7.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (3.1.0)\n",
            "Requirement already satisfied: dask>=2021.12 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (2022.2.0)\n",
            "Collecting scikit-learn<0.25.0,>=0.24.0\n",
            "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting pyrfr<0.9,>=0.8.1\n",
            "  Downloading pyrfr-0.8.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 57.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: distributed>=2012.12 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (2022.2.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.21.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.2.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (6.0)\n",
            "Collecting liac-arff\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "Collecting pynisher<0.7,>=0.6.3\n",
            "  Downloading pynisher-0.6.4.tar.gz (11 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (57.4.0)\n",
            "Collecting distro\n",
            "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.7.3)\n",
            "Collecting smac<1.3,>=1.2\n",
            "  Downloading smac-1.2.tar.gz (260 kB)\n",
            "\u001b[K     |████████████████████████████████| 260 kB 79.6 MB/s \n",
            "\u001b[?25hCollecting ConfigSpace<0.5,>=0.4.21\n",
            "  Downloading ConfigSpace-0.4.21-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 44.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (4.1.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.21->auto-sklearn) (3.0.9)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.21->auto-sklearn) (0.29.32)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.12->auto-sklearn) (1.5.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.12->auto-sklearn) (1.3.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.12->auto-sklearn) (2022.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.12->auto-sklearn) (21.3)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.12->auto-sklearn) (0.12.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (7.1.2)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (2.4.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (1.0.4)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (2.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (2.11.3)\n",
            "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (5.1.1)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (5.4.8)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2012.12->auto-sklearn) (1.7.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->auto-sklearn) (2022.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->auto-sklearn) (2.8.2)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask>=2021.12->auto-sklearn) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0->auto-sklearn) (1.15.0)\n",
            "Collecting emcee>=3.0.0\n",
            "  Downloading emcee-3.1.3-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2012.12->auto-sklearn) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->distributed>=2012.12->auto-sklearn) (2.0.1)\n",
            "Building wheels for collected packages: auto-sklearn, pynisher, smac, liac-arff\n",
            "  Building wheel for auto-sklearn (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for auto-sklearn: filename=auto_sklearn-0.15.0-py3-none-any.whl size=6641946 sha256=d3f2bb5937415d3d40746dc448df7d4187aafe9b13401aa801eb88c3e2bc4105\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/57/ce/ca63ad74b90273f9a682028d187645a42dce5c5255228d46c8\n",
            "  Building wheel for pynisher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynisher: filename=pynisher-0.6.4-py3-none-any.whl size=7043 sha256=1a83a17b376476d74d30f3864cc63c98e9b4fd26dc8fdffe2f0398ad89be2fd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/71/95/7555ec3253e1ba8add72ae5febf1b015d297f3b73ba296d6f6\n",
            "  Building wheel for smac (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smac: filename=smac-1.2-py3-none-any.whl size=215930 sha256=7126aaa1a48106a4f601c04b24864ffc8741c803ff67dea5ad3616246ff3adfc\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/95/67/6afc6b04d3715070c853d0a9d7c7b1fb822def38671dfbbb9f\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11732 sha256=31dc4cbd6c2ec4c38de5a9448a495e87682184a165d8e216197c977bc67b1f1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/0f/15/332ca86cbebf25ddf98518caaf887945fbe1712b97a0f2493b\n",
            "Successfully built auto-sklearn pynisher smac liac-arff\n",
            "Installing collected packages: scikit-learn, pyrfr, pynisher, emcee, ConfigSpace, smac, liac-arff, distro, auto-sklearn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\u001b[0m\n",
            "Successfully installed ConfigSpace-0.4.21 auto-sklearn-0.15.0 distro-1.8.0 emcee-3.1.3 liac-arff-2.5.0 pynisher-0.6.4 pyrfr-0.8.3 scikit-learn-0.24.2 smac-1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install auto-sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Auto-Sklearn\n",
        "\n",
        "# Basic libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
        "\n",
        "# Sklearn\n",
        "## Data\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## Models\n",
        "from sklearn import tree\n",
        "from sklearn import ensemble\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "## Model Explaination\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "## Metrics\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# XGBoost\n",
        "import xgboost\n",
        "\n",
        "# Plotting\n",
        "import graphviz\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "# Auto-Sklearn\n",
        "try:\n",
        "  import autosklearn.regression\n",
        "  import autosklearn.metrics\n",
        "finally:\n",
        "  import autosklearn.regression\n",
        "  import autosklearn.metrics"
      ],
      "metadata": {
        "id": "3cK5O2zIAo_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load Dataset**"
      ],
      "metadata": {
        "id": "DNm_6IWVpM7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "diabetes_data = load_diabetes()\n",
        "predictors = diabetes_data['data']\n",
        "labels = diabetes_data['target']\n",
        "\n",
        "# Print description of the dataset\n",
        "print(diabetes_data['DESCR'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_i2qQJPAtwk",
        "outputId": "7eb5bde8-853f-445a-f202-4c0957e42416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _diabetes_dataset:\n",
            "\n",
            "Diabetes dataset\n",
            "----------------\n",
            "\n",
            "Ten baseline variables, age, sex, body mass index, average blood\n",
            "pressure, and six blood serum measurements were obtained for each of n =\n",
            "442 diabetes patients, as well as the response of interest, a\n",
            "quantitative measure of disease progression one year after baseline.\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "  :Number of Instances: 442\n",
            "\n",
            "  :Number of Attributes: First 10 columns are numeric predictive values\n",
            "\n",
            "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
            "\n",
            "  :Attribute Information:\n",
            "      - age     age in years\n",
            "      - sex\n",
            "      - bmi     body mass index\n",
            "      - bp      average blood pressure\n",
            "      - s1      tc, total serum cholesterol\n",
            "      - s2      ldl, low-density lipoproteins\n",
            "      - s3      hdl, high-density lipoproteins\n",
            "      - s4      tch, total cholesterol / HDL\n",
            "      - s5      ltg, possibly log of serum triglycerides level\n",
            "      - s6      glu, blood sugar level\n",
            "\n",
            "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
            "\n",
            "Source URL:\n",
            "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
            "\n",
            "For more information see:\n",
            "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
            "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "seed = 0\n",
        "\n",
        "# Train - Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(predictors, \n",
        "                                                    labels, \n",
        "                                                    random_state=seed)"
      ],
      "metadata": {
        "id": "IclnVblmCYPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercises**"
      ],
      "metadata": {
        "id": "-P4ETF2DpPHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility functions\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "def get_rmse(model, predictors, labels):\n",
        "  predictions = model.predict(predictors)\n",
        "  rmse = mean_squared_error(labels, predictions, squared=False)\n",
        "  return rmse\n",
        "\n",
        "def rmse_loss(true_labels, pred_labels):\n",
        "  return mean_squared_error(true_labels, pred_labels, squared=False)\n",
        "\n",
        "score_function_decision_tree = make_scorer(rmse_loss, greater_is_better=False)\n"
      ],
      "metadata": {
        "id": "r3_WSu1CpbHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 1a: Fit Decision Tree (Regression)**"
      ],
      "metadata": {
        "id": "dMQO_lLxn1CK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create decision tree regressor object\n",
        "decision_tree_regressor = tree.DecisionTreeRegressor(random_state=seed)\n",
        "\n",
        "# Fit the training data to the regressor\n",
        "decision_tree_regressor = decision_tree_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Calculate root mean square error of the train and test sets\n",
        "train_rmse = get_rmse(decision_tree_regressor, X_train, y_train)\n",
        "test_rmse = get_rmse(decision_tree_regressor, X_test, y_test)\n",
        "\n",
        "# Verbose\n",
        "print(\"Train set root mean squared error is: {} and test set root mean squared error is: {}\".format(round(train_rmse, 4), \n",
        "                                                                                                    round(test_rmse, 4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGH0jJN6rbsJ",
        "outputId": "3d926edd-d057-429d-f93d-97dca7f90b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set root mean squared error is: 0.0 and test set root mean squared error is: 77.4409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 1b: Search for the Best Cost-Complexity Pruning (alpha)**"
      ],
      "metadata": {
        "id": "njnxVPZmn988"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Call built-in method to compute the pruning path during Minimal Cost-Complexity Pruning.\n",
        "path = decision_tree_regressor.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
        "\n",
        "# Define parameter space to search\n",
        "param_grid = { \n",
        "    'ccp_alpha': ccp_alphas,}\n",
        "\n",
        "# Create decision tree classifier object\n",
        "decision_tree_regressor = tree.DecisionTreeRegressor(random_state=seed)\n",
        "\n",
        "# Perform grid search in the defined parameter space with cross validation\n",
        "CV_decision_tree_regressor = GridSearchCV(estimator=decision_tree_regressor, \n",
        "                                          param_grid=param_grid, \n",
        "                                          cv= 5, \n",
        "                                          scoring=score_function_decision_tree)\n",
        "CV_decision_tree_regressor.fit(predictors, labels)\n",
        "\n",
        "# Verbose best parameters from the GridSearchCV\n",
        "print('Best Parameters:', CV_decision_tree_regressor.best_params_)\n",
        "\n",
        "# Fit decision tree model with best parameters\n",
        "decision_tree_regressor = tree.DecisionTreeRegressor(random_state=seed,\n",
        "                                                       **CV_decision_tree_regressor.best_params_)\n",
        "decision_tree_regressor = decision_tree_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Calculate root mean square error of the train and test sets\n",
        "train_rmse = get_rmse(decision_tree_regressor, X_train, y_train)\n",
        "test_rmse = get_rmse(decision_tree_regressor, X_test, y_test)\n",
        "\n",
        "# Verbose\n",
        "print(\"Train set root mean squared error is: {} and test set root mean squared error is: {}\".format(round(train_rmse, 4), \n",
        "                                                                                                    round(test_rmse, 4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b021LF0Xr0E5",
        "outputId": "91466376-09ac-4e3c-f890-a941496d957f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'ccp_alpha': 208.74061453741638}\n",
            "Train set root mean squared error is: 56.1185 and test set root mean squared error is: 66.6557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 2a: Fit an Ensemble Model of Your Choice (Regression)**\n",
        "\n",
        "Helpful to search regression ensemble models, use websites;\n",
        "1. https://scikit-learn.org/stable/modules/ensemble.html\n",
        "2. https://xgboost.readthedocs.io/en/stable/python/python_api.html"
      ],
      "metadata": {
        "id": "siwKWc8DoDdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a XGBoost regressor object\n",
        "xgboost_regressor = xgboost.XGBRegressor(objective ='reg:squarederror')\n",
        "\n",
        "# Fit the training data to the regressor\n",
        "xgboost_regressor = xgboost_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Calculate root mean square error of the train and test sets\n",
        "train_rmse = get_rmse(xgboost_regressor, X_train, y_train)\n",
        "test_rmse = get_rmse(xgboost_regressor, X_test, y_test)\n",
        "print(\"Train set root mean squared error is: {} and test set root mean squared error is: {}\".format(round(train_rmse, 4), \n",
        "                                                                                                    round(test_rmse, 4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f31Q_EPYwy2K",
        "outputId": "e53e022a-2d70-41fa-f2ef-16d71da2bc28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set root mean squared error is: 29.122 and test set root mean squared error is: 62.0087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 2b: Search Hyperparameter Space of your Choice of Model**"
      ],
      "metadata": {
        "id": "or9sU2MhoPC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameter space to search\n",
        "param_grid = {\n",
        "    'n_estimators': [20, 50, 100],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'learning_rate': [0.1, 0.3, 0.5, 0.7],\n",
        "    'min_child_weight': [1, 10, 100, 200, 500],\n",
        "    'colsample_bytree': [0.1, 0.3, 0.7],\n",
        "}\n",
        "\n",
        "# Create decision tree classifier object\n",
        "xgboost_regressor = xgboost.XGBRegressor(objective ='reg:squarederror')\n",
        "\n",
        "# Perform grid search in the defined parameter space with cross validation\n",
        "CV_xgboost_regressor = GridSearchCV(estimator=xgboost_regressor, \n",
        "                                    param_grid=param_grid, \n",
        "                                    cv= 5, \n",
        "                                    scoring=score_function_decision_tree)\n",
        "CV_xgboost_regressor.fit(predictors, labels)\n",
        "\n",
        "# Verbose best parameters from the GridSearchCV\n",
        "print('Best Parameters:', CV_xgboost_regressor.best_params_)\n",
        "\n",
        "# Fit decision tree model with best parameters\n",
        "xgboost_regressor = xgboost.XGBRegressor(objective ='reg:squarederror',\n",
        "                                         **CV_xgboost_regressor.best_params_)\n",
        "xgboost_regressor = xgboost_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Calculate root mean square error of the train and test sets\n",
        "train_rmse = get_rmse(xgboost_regressor, X_train, y_train)\n",
        "test_rmse = get_rmse(xgboost_regressor, X_test, y_test)\n",
        "\n",
        "# Verbose\n",
        "print(\"Train set root mean squared error is: {} and test set root mean squared error is: {}\".format(round(train_rmse, 4), \n",
        "                                                                                                    round(test_rmse, 4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8clxC6hyjjy",
        "outputId": "1441529c-bb4d-4838-8735-ac84f4a704b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.5, 'max_depth': 3, 'min_child_weight': 100, 'n_estimators': 50}\n",
            "Train set root mean squared error is: 48.5722 and test set root mean squared error is: 60.4998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 3 (Bonus): Use AutoML to Improve RMSE Metric**"
      ],
      "metadata": {
        "id": "oTTWj4mZod5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define AutoML regression model from Auto-Sklearn\n",
        "automl = autosklearn.regression.AutoSklearnRegressor(time_left_for_this_task=120,\n",
        "                                                     metric=autosklearn.metrics.root_mean_squared_error)\n",
        "\n",
        "# Fit AutoML regression model \n",
        "automl.fit(X_train, y_train)\n",
        "\n",
        "# Calculate root mean square error of the train and test sets\n",
        "train_rmse = get_rmse(automl, X_train, y_train)\n",
        "test_rmse = get_rmse(automl, X_test, y_test)\n",
        "\n",
        "# Verbose\n",
        "print(\"Train set root mean squared error is: {} and test set root mean squared error is: {}\".format(round(train_rmse, 4), \n",
        "                                                                                                    round(test_rmse, 4)))\n",
        "\n",
        "# Verbose Final Model Leaderboard from AutoML\n",
        "print(automl.leaderboard())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpV8DtZd0Aby",
        "outputId": "bdfed2a7-737e-4544-eca4-e43e43aaa9e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set root mean squared error is: 49.3364 and test set root mean squared error is: 56.0331\n",
            "          rank  ensemble_weight           type       cost  duration\n",
            "model_id                                                           \n",
            "25           1             0.66            sgd  51.472196  0.557539\n",
            "49           2             0.08  liblinear_svr  51.999036  0.569245\n",
            "48           3             0.14  liblinear_svr  53.439187  0.550245\n",
            "11           4             0.12  random_forest  55.999621  7.964592\n"
          ]
        }
      ]
    }
  ]
}